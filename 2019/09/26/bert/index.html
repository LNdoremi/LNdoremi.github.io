<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="原文地址：https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/ BERT - NLP最先进的语言模型BERT(Bidirectional Encoder Representation from Transformers) 是最近谷歌AI语言研究员发表的一篇文章。它已经在机器学习社">
<meta name="keywords" content="nlp,translation">
<meta property="og:type" content="article">
<meta property="og:title" content="Bert">
<meta property="og:url" content="http://yoursite.com/2019/09/26/bert/index.html">
<meta property="og:site_name" content="LNdoremi">
<meta property="og:description" content="原文地址：https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/ BERT - NLP最先进的语言模型BERT(Bidirectional Encoder Representation from Transformers) 是最近谷歌AI语言研究员发表的一篇文章。它已经在机器学习社">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/images/bert/1.png">
<meta property="og:image" content="http://yoursite.com/images/bert/2.png">
<meta property="og:image" content="http://yoursite.com/images/bert/3.png">
<meta property="og:image" content="http://yoursite.com/images/bert/4.png">
<meta property="og:updated_time" content="2019-09-29T06:06:38.848Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bert">
<meta name="twitter:description" content="原文地址：https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/ BERT - NLP最先进的语言模型BERT(Bidirectional Encoder Representation from Transformers) 是最近谷歌AI语言研究员发表的一篇文章。它已经在机器学习社">
<meta name="twitter:image" content="http://yoursite.com/images/bert/1.png">
  <link rel="canonical" href="http://yoursite.com/2019/09/26/bert/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Bert | LNdoremi</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LNdoremi</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/26/bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LNdoremi">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LNdoremi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">Bert

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-26 15:50:17" itemprop="dateCreated datePublished" datetime="2019-09-26T15:50:17+08:00">2019-09-26</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-29 14:06:38" itemprop="dateModified" datetime="2019-09-29T14:06:38+08:00">2019-09-29</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/translation/" itemprop="url" rel="index"><span itemprop="name">translation</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>原文地址：<a href="https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/" target="_blank" rel="noopener">https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/</a></p>
<h3 id="BERT-NLP最先进的语言模型"><a href="#BERT-NLP最先进的语言模型" class="headerlink" title="BERT - NLP最先进的语言模型"></a>BERT - NLP最先进的语言模型</h3><p>BERT(Bidirectional Encoder Representation from Transformers) 是最近谷歌AI语言研究员发表的一篇文章。它已经在机器学习社区引起了骚动，因为它在多个NLP任务中取得了最先进的结果，包括问答、自然语言推断等。</p>
<p>BERT关键的技术创新在于将transformer的双向训练（流行的注意力模型）应用在语言建模中。这与以往的方法形成对比，无论是从左到右还是结合从左到右和从右到左训练文本序列。论文结果表明：双向训练的语言模型比起单向语言模型，对语言文本有更深的理解。在论文中，研究人员详尽阐述了创新的技术Masked LM (MLM)，实现了在模型中使用双向训练，这在以往是不可能的。</p>
<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>在计算机视觉领域，研究人员发现迁移学习很有效，比如ImageNet，在已知任务上预训练神经网络模型，然后在新的指定任务上进行微调。近来，研究人员证实了相似的技术在许多自然语言任务中也很有效。<br>另有一个方法feature-based training，在NLP任务中也很流行，在最近的ELMo论文中例证了。在这个方法中，预训练的神经网络产生word embeddings——随后作为NLP模型的特征。</p>
<h3 id="How-BERT-works"><a href="#How-BERT-works" class="headerlink" title="How BERT works"></a>How BERT works</h3><p>BERT利用Transformer——注意力机制——学习文本中词语之间的上下文关系。在Transformer最原始的形式中，包含两个分离的机制——一个读取文本的编码器，一个为任务产生预测的解码器。因为BERT的目标是生成一个语言模型，只需要一个编码器。谷歌另一篇论文详细阐述了Transformer的原理。<br>与方向性模型形成鲜明对比，transformer编码器一次性读取整串词，其它模型按顺序读取文本（从左到右或者从右到左）。因此transformer被看作是双向的，尽管称为无方向更准确。这个特征让模型学习词的语义——基于它所有的周围的词（左边和右边的词）。<br>下图很好的描述了transformer encoder。输入是一串token，先嵌入成向量，然后放入神经网络中处理。输出是一个大小为H的向量，每个向量对应一个相同index的输入token。<br><img src="/images/bert/1.png" alt="transformer encoder"><br>训练语言模型时，如何定义预测目标是一个问题。许多模型预测序列中的下一个词（e.g. “The child came home from ___”），方向性的方法自身限制了上下文学习。BERT使用两种训练策略，解决这个问题。</p>
<h3 id="Masked-LM-MLM"><a href="#Masked-LM-MLM" class="headerlink" title="Masked LM(MLM)"></a>Masked LM(MLM)</h3><p>将单词序列放进BERT之前，每个序列中15%的被[MASK]token代替，模型根据句中没有被掩盖的上下文来预测被掩盖的词的原意。从技术层面来讲，预测输出的词需要以下几点：</p>
<ol>
<li>在encoder输出层顶部添加分类层；</li>
<li>将输出向量与嵌入矩阵相乘，变换成vocabulary维度；</li>
<li>用softmax计算每个单词在词表中的概率。<br><img src="/images/bert/2.png" alt="transformer encoder"></li>
</ol>
<p>BERT损失函数只考虑掩盖值的预测，忽略未掩盖词的预测。因此，模型比方向性模型收敛得更慢，也因如此，提升了上下文的感知。<br>注意：在实践中，BERT的实现稍微精细一些，并不是替换全部15%掩盖的词汇。</p>
<h3 id="Next-Sentence-Prediction-NSP"><a href="#Next-Sentence-Prediction-NSP" class="headerlink" title="Next Sentence Prediction(NSP)"></a>Next Sentence Prediction(NSP)</h3><p>在BERT的训练过程中，模型接收一些句子作为输入，学习去预测第二个句子在原文中是否是下一句。在训练中，50%的输入是第二句话在原文中是下一句，另外50%是从语料中随机选择的句子作为语料。假定随机的句子与第一句没有关联。</p>
<p>训练时为了帮助模型区分两个句子，输入的句子会做如下的处理：</p>
<ol>
<li>[CLS]token被插入到第一个句子的开头，[SEP]token被插入到每个句子的最后。</li>
<li>代表句子A与句子B的句向量加到每个token上；</li>
<li>代表位置信息的位置向量加到每个token上。<br><img src="/images/bert/3.png" alt="transformer encoder"></li>
</ol>
<p>预测第二句话是否与第一句话相关，执行以下几个步骤：</p>
<ol>
<li>将全部序列输入Transformer模型中；</li>
<li>将输出的[CLS]token变换成2*1的向量；</li>
<li>使用softmax计算IsNextSequence的概率。<br>训练BERT模型时，Masked LM 和 Next Sentence Prediction 是一起训练的，目标是将二种策略的损失函数降到最低。</li>
</ol>
<h3 id="How-to-use-BERT-Fine-tuning"><a href="#How-to-use-BERT-Fine-tuning" class="headerlink" title="How to use BERT(Fine-tuning)"></a>How to use BERT(Fine-tuning)</h3><p>使用BERT完成指定的任务非常的简明：<br>BERT可以用来做很多语言任务，只需要在核心模型中添加一个小层：</p>
<ol>
<li>像情感分析这样的分类任务与下一句分类相似，在transformer输出[CLS]token的顶层添加一个分类层。</li>
<li>在问答任务中，软件接收问题的文本序列，需要在序列中标记答案。使用BERT，可以通过学习两个额外的向量——标记了答案的起点和终点，来训练问答模型。</li>
<li>在命名实体识别（NER）中，软件接收一个文本序列，标记出文本中出现的不同的实体（人名，机构，日期等）。使用BERT，可以将每个token输出的向量放入预测NER标签的分类层来训练NER模型。</li>
</ol>
<p>在fine-tuning训练中，大部分的超参和BERT训练保持一致，并且论文给出了需要调节的超参的详细指导。BERT团队使用这个技术在很多具有挑战性的自然语言任务中取得了最先进的成果。<br>注意：BERT预训练模型也可以用来生成文本向量，与其它基于特征的模型相似，比如说doc2vec和ELMo。论文发现连接编码器最后四层可以获得最好的嵌入向量。</p>
<h3 id="Takeaways"><a href="#Takeaways" class="headerlink" title="Takeaways"></a>Takeaways</h3><ol>
<li>模型的大小会有影响，即便是大规模。BERT LARGE有345百万的参数，是最大的BERT模型，证实了比小规模的BERT BASE效果好，BERT BASE与 BERT LARGE原理相同，只不过“只有”110百万个参数。</li>
<li>有足够的训练数据时，更多的训练步骤 == 更高的精度。举个例子，在MNLI任务中，使用相同的batch size，训练步数由1M变为500k时，BERT BASE精度提升了1.0%。</li>
<li>BERT双向方法（MLM）比从左到右的方法收敛得慢，因为每次只有15%的的词被预测。然而在少量的预训练步骤之后，双向训练依旧优于从左到右的训练。<br><img src="/images/bert/4.png" alt="transformer encoder"></li>
</ol>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>BERT毫无疑问在自然语言处理的机器学习领域取得了重大的突破。它的可接触性、允许快速的fine-tuning在未来很有可能被广泛的实践与应用。</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/nlp/" rel="tag"># nlp</a>
            
              <a href="/tags/translation/" rel="tag"># translation</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/09/18/gec/" rel="next" title="gec">
                  <i class="fa fa-chevron-left"></i> gec
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/09/27/mid-autum/" rel="prev" title="mid-autum">
                  mid-autum <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#BERT-NLP最先进的语言模型"><span class="nav-number">1.</span> <span class="nav-text">BERT - NLP最先进的语言模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Background"><span class="nav-number">2.</span> <span class="nav-text">Background</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-BERT-works"><span class="nav-number">3.</span> <span class="nav-text">How BERT works</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Masked-LM-MLM"><span class="nav-number">4.</span> <span class="nav-text">Masked LM(MLM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Next-Sentence-Prediction-NSP"><span class="nav-number">5.</span> <span class="nav-text">Next Sentence Prediction(NSP)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-use-BERT-Fine-tuning"><span class="nav-number">6.</span> <span class="nav-text">How to use BERT(Fine-tuning)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Takeaways"><span class="nav-number">7.</span> <span class="nav-text">Takeaways</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conclusion"><span class="nav-number">8.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="LNdoremi">
  <p class="site-author-name" itemprop="name">LNdoremi</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/LNdoremi" title="GitHub &rarr; https://github.com/LNdoremi" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="/liuna_sysu@qq.com" title="E-Mail &rarr; liuna_sysu@qq.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.archao.me/" title="https://www.archao.me/" rel="noopener" target="_blank">Chao</a>
        </li>
      
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LNdoremi</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/muse.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  

  

</body>
</html>
